{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import h5py\n",
    "import scipy.io\n",
    "\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = h5py.File('somefile.mat','r')\n",
    "matdata=scipy.io.loadmat('dataForPythonBIMcmplx25dB.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hatm=matdata['Hatm']\n",
    "Atm=matdata['Atm']\n",
    "N=int((matdata['N']))\n",
    "targetsR=matdata['d_epsaM']\n",
    "targetsI=np.zeros_like(targetsR)\n",
    "nMeas=int((matdata['nMeas']))\n",
    "nRx=int((matdata['nRx']))\n",
    "nTx=int((matdata['nTx']))\n",
    "Np=int((matdata['Np']))\n",
    "Emea=matdata['Emea']\n",
    "Einc=matdata['Ez_inc']\n",
    "#a1tm=matdata['a1tm']\n",
    "#a1tmC=matdata['a1tmC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 4608)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets=np.concatenate((targetsR,targetsI),axis=1)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 28, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs=Emea\n",
    "Emea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=torch.tensor(inputs,dtype = torch.complex64)\n",
    "targets=torch.tensor(targets,dtype = torch.float32)\n",
    "Hatm=torch.tensor(Hatm,dtype = torch.complex64)\n",
    "Atm=torch.tensor(Atm,dtype = torch.complex128)\n",
    "Einc=torch.tensor(Einc,dtype = torch.complex128)\n",
    "#a1tm=torch.tensor(a1tm,dtype = torch.complex64)\n",
    "#a1tmC=torch.tensor(a1tmC,dtype = torch.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1tm=Atm[0,:].reshape(Np,Np)\n",
    "a1tm=torch.cat((a1tm[range(Np-1,-1,-1),:],a1tm[range(1,Np,1),:]),dim=0)\n",
    "a1tm=torch.cat((a1tm[:,range(Np-1,-1,-1)],a1tm[:,range(1,Np,1)]),dim=1)\n",
    "a1tmC=torch.fft.fft2(a1tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valSize=2000\n",
    "testingSize=2000\n",
    "trainingSize=len(inputs)-(valSize+testingSize)\n",
    "train_in, val_in, test_in = torch.split(inputs, [trainingSize, valSize, testingSize])\n",
    "train_tr, val_tr, test_tr = torch.split(targets, [trainingSize, valSize, testingSize])\n",
    "train_ds = TensorDataset(train_in, train_tr)\n",
    "val_ds = TensorDataset(val_in, val_tr)\n",
    "test_ds = TensorDataset(test_in, test_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#print(len(dataset[0:10]))\n",
    "print(len(train_ds))\n",
    "print(len(val_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "test_dl = DeviceDataLoader(test_dl, device)\n",
    "Hatm=to_device(Hatm, device)\n",
    "Atm=to_device(Atm, device)\n",
    "Einc=to_device(Einc, device)\n",
    "a1tm=to_device(a1tm, device)\n",
    "a1tmC=to_device(a1tmC, device)\n",
    "inputs=to_device(inputs, device)\n",
    "targets=to_device(targets, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRegressionBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, targets = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.mse_loss(out, targets) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, targets = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.mse_loss(out, targets)   # Calculate loss\n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "negSlop=0.1\n",
    "def conv_block(in_channels, out_channels):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.LeakyReLU(negSlop,inplace=True),\n",
    "              nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.LeakyReLU(negSlop,inplace=True)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv_block_downsampling(in_channels, out_channels):\n",
    "    layers=nn.ModuleList()\n",
    "    layers.append(nn.MaxPool2d(2, stride=2))\n",
    "    layers.append(conv_block(in_channels, out_channels))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv_block_upsampling(in_channels, out_channels):\n",
    "    layers=nn.ModuleList()\n",
    "    layers.append(conv_block(2*in_channels, in_channels))\n",
    "    layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, bias=False))\n",
    "    layers.append(nn.LeakyReLU(negSlop,inplace=True))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv_block_upsamplingF(in_channels, out_channels):\n",
    "    layers=nn.ModuleList()\n",
    "    layers.append(conv_block(2*in_channels, in_channels))\n",
    "    layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "    layers.append(nn.LeakyReLU(negSlop,inplace=True))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "Nfltr=32\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.down1 = conv_block(in_channels,Nfltr) #conv_block_downsampling(in_channels, 64,pool=False)\n",
    "        self.down2 = conv_block_downsampling(Nfltr, 2*Nfltr)\n",
    "        self.down3 = conv_block_downsampling(2*Nfltr,4*Nfltr)\n",
    "        self.down4 = nn.ModuleList()\n",
    "        self.down4.append(conv_block_downsampling(4*Nfltr, 8*Nfltr))\n",
    "        self.down4.append(nn.ConvTranspose2d(8*Nfltr, 4*Nfltr, kernel_size=2, stride=2, bias=False))\n",
    "        self.down4.append(nn.LeakyReLU(negSlop,inplace=True))\n",
    "        self.down4=nn.Sequential(*self.down4)\n",
    "        \n",
    "        self.up1=conv_block_upsampling(4*Nfltr, 2*Nfltr)\n",
    "        self.up2=conv_block_upsampling(2*Nfltr, Nfltr)\n",
    "        self.up3=conv_block_upsamplingF(Nfltr, in_channels)\n",
    "        \n",
    "    def forward(self, d_epsR,d_epsI):\n",
    "        xb=torch.cat((d_epsR,d_epsI),dim=1)\n",
    "        xb=torch.reshape(xb,(-1,self.in_channels,Np,Np))\n",
    "        out1 = self.down1(xb)\n",
    "        out2=self.down2(out1)\n",
    "        out3=self.down3(out2)\n",
    "        out4=self.down4(out3)\n",
    "        out5=self.up1(torch.cat((out3,out4),dim=1))\n",
    "        out6=self.up2(torch.cat((out2,out5),dim=1))\n",
    "        out7=self.up3(torch.cat((out1,out6),dim=1))\n",
    "        out=torch.reshape(out7,(-1,self.in_channels*N))\n",
    "        return out[:,0:N], out[:,N:2*N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HmatMult(Etot,d_eps):\n",
    "    nbatch=d_eps.shape[1]\n",
    "    xout=to_device(torch.zeros((nRx,nbatch,nTx),dtype=torch.complex64), device)\n",
    "    temp=to_device(torch.zeros((N,nbatch),dtype=torch.complex64), device)\n",
    "    for tr in range(nTx):\n",
    "        temp=Etot[:,:,tr]*d_eps\n",
    "        xout[:,:,tr]=Hatm@temp\n",
    "    return -xout\n",
    "\n",
    "def HmatconjMult(Etot,xin):\n",
    "    nbatch=xin.shape[1]\n",
    "    xout=to_device(torch.zeros((N,nbatch)), device)\n",
    "    for tr in range(nTx):\n",
    "        xout=xout+Etot[:,:,tr].conj()*(Hatm.t().conj()@xin[:,:,tr])\n",
    "    return -xout\n",
    "\n",
    "\n",
    "def soft_thresholding(d_eps,delta):\n",
    "    nbatch=d_eps.shape[1]\n",
    "    maxi=torch.zeros_like(d_eps)\n",
    "    maxi=torch.maximum(d_eps.abs()-delta,torch.zeros_like(d_eps.real))\n",
    "    d_eps=(maxi*d_eps)/(maxi+delta);\n",
    "    return d_eps\n",
    "\n",
    "  \n",
    "\n",
    "def BiCGFFTtm(d_eps,y,nmax):\n",
    "    y=torch.reshape(y,(N,1))\n",
    "    nbatch=d_eps.shape[1]\n",
    "    xout=to_device(torch.zeros((N,nbatch),dtype= torch.complex64), device)\n",
    "    if torch.sum(torch.abs(d_eps))<=0.0000000000001:\n",
    "        temp=to_device(torch.zeros((N,nbatch),dtype= torch.complex64), device)\n",
    "        xout=y-temp\n",
    "        del temp\n",
    "    else:\n",
    "        rhoi=1.0*to_device(torch.ones((nbatch),dtype= torch.complex128), device)\n",
    "        alpha=1.0*to_device(torch.ones((nbatch),dtype= torch.complex128), device)\n",
    "        w=1.0*to_device(torch.ones((nbatch),dtype= torch.complex128), device)\n",
    "        v=to_device(torch.zeros((N,nbatch),dtype= torch.complex128), device)\n",
    "        p=to_device(torch.zeros((N,nbatch),dtype= torch.complex128), device)\n",
    "        x=to_device(torch.zeros((N,nbatch),dtype= torch.complex128), device)\n",
    "        temp=to_device(torch.zeros((N,nbatch)), device)\n",
    "        temp=AmultFFT(d_eps,x)\n",
    "        r=y-temp\n",
    "        rhat0=r\n",
    "        for cg_iter in range(nmax):\n",
    "            rhoi_1=rhoi\n",
    "            rhoi=torch.sum(rhat0*r,dim=0)\n",
    "            beta=(rhoi/rhoi_1)*(alpha/w)\n",
    "            p=r+beta*(p-w*v)\n",
    "            v=AmultFFT(d_eps,p)\n",
    "            alpha=rhoi/(torch.sum(rhat0*v,dim=0))\n",
    "            s=r-alpha*v\n",
    "            t=AmultFFT(d_eps,s)\n",
    "            w=(torch.sum(t*s,dim=0))/(torch.sum(t*t,dim=0))\n",
    "            x=x+alpha*p+w*s\n",
    "            r=s-w*t\n",
    "        xout=x\n",
    "    return xout  \n",
    "\n",
    "\n",
    "\n",
    "def AmultFFT(deps,xi):\n",
    "    xi=xi.permute(1,0)\n",
    "    deps=deps.permute(1,0)\n",
    "    nbatch=deps.shape[0]\n",
    "    x=to_device(torch.zeros((nbatch,2*Np-1,2*Np-1),dtype=torch.complex128),device)\n",
    "    x[:,0:Np,0:Np]=torch.reshape(deps*xi,(-1,Np,Np))\n",
    "    xfft=torch.fft.fft2(x)\n",
    "    x=a1tmC*xfft\n",
    "    out=torch.fft.ifft2(x)\n",
    "    out=out[:,Np-1:2*Np-1,Np-1:2*Np-1]\n",
    "    out=out.reshape(nbatch,N)\n",
    "    out=out+xi\n",
    "    return out.permute(1,0)\n",
    "\n",
    "def BiCGtmFFTloop(d_eps,Einc,nmax):\n",
    "    nbatch=d_eps.shape[1]\n",
    "    Etot=to_device(torch.zeros((N,nbatch,nTx),dtype= torch.complex64), device)\n",
    "    for tr in range(nTx):\n",
    "        Etot[:,:,tr]=BiCGFFTtm(d_eps,Einc[:,tr],nmax)\n",
    "    return Etot\n",
    "\n",
    "\n",
    "def power(Etot,maxit):\n",
    "    nbatch=Etot.shape[1]\n",
    "    x=to_device(torch.rand((N,nbatch),dtype= torch.complex64), device)\n",
    "    xn=to_device(torch.zeros((N,nbatch),dtype= torch.complex64), device)\n",
    "    xm=to_device(torch.zeros((N,nbatch),dtype= torch.complex64), device)\n",
    "    xm = HmatMult(Etot,x)\n",
    "    xn = HmatconjMult(Etot,xm)\n",
    "    lammda=torch.sum(x*xn,dim=0)/torch.sum(x*x,dim=0)\n",
    "    x=x/torch.max(x.abs(),dim=0).values\n",
    "    for itr in range(maxit):\n",
    "        xm = HmatMult(Etot,x)\n",
    "        x = HmatconjMult(Etot,xm)\n",
    "        xm = HmatMult(Etot,x)\n",
    "        xn = HmatconjMult(Etot,xm)\n",
    "        lammda0=lammda\n",
    "        lammda=torch.sum(x*xn,dim=0)/torch.sum(x*x,dim=0)\n",
    "        x=x/torch.max(x.abs(),dim=0).values\n",
    "        error=torch.abs(lammda-lammda0)/torch.abs(lammda)\n",
    "    return 1/lammda.real\n",
    "\n",
    "    \n",
    "class ComputeBornSVD(ImageRegressionBase):\n",
    "    def __init__(self,regNet1,regNet2,regNet3,nLW,nbim_iter,nmax,maxit):\n",
    "        super().__init__()\n",
    "        self.regNet1=regNet1\n",
    "        self.regNet2=regNet2\n",
    "        self.regNet3=regNet3\n",
    "        self.nLW=nLW\n",
    "        self.nbim_iter=nbim_iter\n",
    "        self.nmax=nmax\n",
    "        self.maxit=maxit\n",
    "        Etot=to_device(torch.zeros((N,1,nTx),dtype= torch.complex64), device)\n",
    "        Etot[:,0,:]=Einc[:,:]\n",
    "        self.gamma0=power(Etot,maxit)\n",
    "        print(self.gamma0)\n",
    "        \n",
    "    def forward(self, Emea):\n",
    "        nbatch=Emea.shape[0]\n",
    "        d_eps=to_device(torch.zeros((N,nbatch),dtype= torch.complex64), device)\n",
    "        Etot=to_device(torch.zeros((N,nbatch,nTx),dtype= torch.complex64), device)\n",
    "\n",
    "        for batch in range(nbatch):\n",
    "            Etot[:,batch,:]=Einc[:,:]\n",
    "        \n",
    "        for bim_itr in range(self.nbim_iter):\n",
    "            if bim_itr==0:\n",
    "                gamma=self.gamma0\n",
    "            else:\n",
    "                gamma=power(Etot,self.maxit)  \n",
    "        \n",
    "            for lw_itr in range(self.nLW):\n",
    "                xout = HmatMult(Etot,d_eps)\n",
    "                misfit=Emea.permute(1,0,2)-xout\n",
    "                xout = HmatconjMult(Etot,misfit)\n",
    "                d_eps=d_eps+gamma*xout\n",
    "                if bim_itr==0:\n",
    "                    d_epsR,d_epsI=self.regNet1(d_eps.permute(1,0).real,d_eps.permute(1,0).imag)\n",
    "                elif bim_itr==1:\n",
    "                    d_epsR,d_epsI=self.regNet2(d_eps.permute(1,0).real,d_eps.permute(1,0).imag)\n",
    "                elif bim_itr==2:\n",
    "                    d_epsR,d_epsI=self.regNet3(d_eps.permute(1,0).real,d_eps.permute(1,0).imag)\n",
    "                #d_eps=soft_thresholding(d_eps,0.001)\n",
    "                 \n",
    "                d_eps=torch.complex(d_epsR,d_epsI); d_eps=d_eps.permute(1,0)\n",
    "            if bim_itr<(self.nbim_iter-1):\n",
    "                Etot=BiCGtmFFTloop(d_eps,Einc, self.nmax)\n",
    "                \n",
    "        \n",
    "        d_eps=d_eps.permute(1,0)\n",
    "        return torch.cat((d_eps.real,d_eps.imag),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This initiate a model that runs over a single TBIM iteration, nbim_iter=1\n",
    "regNet1=Unet(in_channels=2)\n",
    "regNet2=Unet(in_channels=2)\n",
    "regNet3=Unet(in_channels=2)\n",
    "model = to_device(ComputeBornSVD(regNet1=regNet1,regNet2=regNet2,regNet3=regNet3,nLW=6,nbim_iter=1,nmax=4,maxit=6), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00005, train_loss: 0.0072, val_loss: 0.0022\n",
      "Epoch [1], last_lr: 0.00014, train_loss: 0.0017, val_loss: 0.0015\n",
      "Epoch [2], last_lr: 0.00026, train_loss: 0.0012, val_loss: 0.0011\n",
      "Epoch [3], last_lr: 0.00038, train_loss: 0.0010, val_loss: 0.0011\n",
      "Epoch [4], last_lr: 0.00047, train_loss: 0.0008, val_loss: 0.0008\n",
      "Epoch [5], last_lr: 0.00050, train_loss: 0.0007, val_loss: 0.0007\n",
      "Epoch [6], last_lr: 0.00049, train_loss: 0.0006, val_loss: 0.0006\n",
      "Epoch [7], last_lr: 0.00048, train_loss: 0.0005, val_loss: 0.0005\n",
      "Epoch [8], last_lr: 0.00045, train_loss: 0.0005, val_loss: 0.0005\n",
      "Epoch [9], last_lr: 0.00041, train_loss: 0.0004, val_loss: 0.0005\n",
      "Epoch [10], last_lr: 0.00036, train_loss: 0.0004, val_loss: 0.0005\n",
      "Epoch [11], last_lr: 0.00031, train_loss: 0.0004, val_loss: 0.0004\n",
      "Epoch [12], last_lr: 0.00025, train_loss: 0.0004, val_loss: 0.0004\n",
      "Epoch [13], last_lr: 0.00019, train_loss: 0.0003, val_loss: 0.0004\n",
      "Epoch [14], last_lr: 0.00014, train_loss: 0.0003, val_loss: 0.0004\n",
      "Epoch [15], last_lr: 0.00009, train_loss: 0.0003, val_loss: 0.0003\n",
      "Epoch [16], last_lr: 0.00005, train_loss: 0.0003, val_loss: 0.0003\n",
      "Epoch [17], last_lr: 0.00002, train_loss: 0.0003, val_loss: 0.0003\n",
      "Epoch [18], last_lr: 0.00001, train_loss: 0.0003, val_loss: 0.0003\n",
      "Epoch [19], last_lr: 0.00000, train_loss: 0.0003, val_loss: 0.0003\n",
      "Wall time: 1h 21min 55s\n"
     ]
    }
   ],
   "source": [
    "#To perform model training that runs over single TBIM iteration\n",
    "%%time\n",
    "epochs = 20\n",
    "max_lr = 0.0005\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam\n",
    "history1 += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n",
    "                             opt_func=opt_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0001], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# This initiate a model that runs over two TBIM iterations, nbim_iter=2, the regularization networks of the first iteration step is taken from the previous training\n",
    "model = to_device(ComputeBornSVD(regNet1=model.regNet1,regNet2=model.regNet2,regNet3=model.regNet3,nLW=6,nbim_iter=2,nmax=4,maxit=5), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze the first TBIM regularization Network\n",
    "for param in model.regNet1.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00007, train_loss: 0.0006, val_loss: 0.0004\n",
      "Epoch [1], last_lr: 0.00019, train_loss: 0.0003, val_loss: 0.0003\n",
      "Epoch [2], last_lr: 0.00025, train_loss: 0.0003, val_loss: 0.0004\n",
      "Epoch [3], last_lr: 0.00024, train_loss: 0.0003, val_loss: 0.0003\n",
      "Epoch [4], last_lr: 0.00020, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [5], last_lr: 0.00015, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [6], last_lr: 0.00010, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [7], last_lr: 0.00005, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [8], last_lr: 0.00001, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [9], last_lr: 0.00000, train_loss: 0.0002, val_loss: 0.0002\n",
      "Wall time: 3h 4min 46s\n"
     ]
    }
   ],
   "source": [
    "# Train the regulrization network for only the second TBIM, and use the prevoius trained network for the first TBIM iteration \n",
    "%%time\n",
    "epochs = 10\n",
    "max_lr = 0.00025\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam\n",
    "history2 += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0001], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# This initiate a model that runs over three TBIM iterations, nbim_iter=3, the regularization networks of the first and second iteration steps are taken from the previous training\n",
    "model = to_device(ComputeBornSVD(regNet1=model.regNet1,regNet2=model.regNet2,regNet3=model.regNet3,nLW=6,nbim_iter=3,nmax=4,maxit=5), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze the first and second TBIM regularization Network\n",
    "for param in model.regNet1.parameters():\n",
    "    param.requires_grad=False\n",
    "for param in model.regNet2.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00015, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [1], last_lr: 0.00019, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [2], last_lr: 0.00012, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [3], last_lr: 0.00004, train_loss: 0.0002, val_loss: 0.0003\n",
      "Epoch [4], last_lr: 0.00000, train_loss: 0.0002, val_loss: 0.0003\n",
      "Wall time: 2h 43min 30s\n"
     ]
    }
   ],
   "source": [
    "# Train the regulrization network for only the third TBIM, and use the prevoius trained networks for the first and second TBIM iteration \n",
    "%%time\n",
    "epochs = 5\n",
    "max_lr = 0.0002\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam\n",
    "history3=[]\n",
    "history3 += fit_one_cycle(epochs, max_lr, model3, train_dl, val_dl, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained regularization network for the first,second, and third TBIM iteration regNet1, regNet2, and regNet3\n",
    "torch.save(model.regNet1.state_dict(),\"regNet1\")\n",
    "torch.save(model.regNet2.state_dict(),\"regNet2\")\n",
    "torch.save(model.regNet3.state_dict(),\"regNet3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save histories\n",
    "torch.save(history1,\"history1\")\n",
    "torch.save(history2,\"history2\")\n",
    "torch.save(history3,\"history3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To plot histories\n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "plot_losses(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the RNEs model\n",
    "%%time\n",
    "def RNE_batch(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        RNEm=[]\n",
    "        for imageI,imageO in inputs:\n",
    "            nbatch=imageI.shape[0]\n",
    "            xLW=model(imageI)\n",
    "            RNE=[100*torch.linalg.norm(xLW[indx:indx+1,:]-imageO[indx:indx+1,:], ord='fro')/torch.linalg.norm(imageO[indx:indx+1,:], ord='fro') for indx in range(nbatch)]\n",
    "            RNE=[torch.stack(RNE).mean()]\n",
    "            RNEm=RNEm+RNE\n",
    "        RNEM=torch.stack(RNEm).mean()\n",
    "    return RNEM\n",
    "\n",
    "RNE=RNE_batch(model, test_dl)\n",
    "print(RNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the MSE (loss function) of the testing examples\n",
    "resTest = evaluate(model, test_dl)\n",
    "resTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
